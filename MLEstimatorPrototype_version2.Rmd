---
title: "Maximum Likelihood Estimators Module Prototype (Without Using Hessian)"
output: html_notebook
---

<h2>Program Modules:</h2>
<br>
<h3>Newton Iteration Module</h3>
<br>
<h4>Gradient Computation Methods</h4>

```{r}
# For log-likelihood of gamma distribution expressed in terms of alpha parameter
get_gamma_gradient <- function(W, X) { # W contains parameter; X is the sample_data
  
  # Extracting parameters from W into variables that better elucidate what they are
  alpha <- W
  
  # Computing size of sample data
  sample_size <- length(X)
  
  # first order derivative of log-likelihood function expressed in terms of primary parameter
  gradient <- sample_size * (log(alpha) - log(mean(sample_data)) - digamma(alpha)) + sum(log(sample_data))
  
  return(gradient)
}
```

```{r}
# For log-likelihood of normal distribution expressed in terms of alpha parameter
get_normal_gradient <- function(W, X) { # W contains parameter; X is the sample_data
  
  # Extracting parameters from W into variables that better elucidate what they are
  mu <- W
  
  # Computing size of sample data
  sample_size <- length(X)
  
  variance <- sum((sample_data - mu) ^ 2) / sample_size
  # first order derivative of log-likelihood function expressed in terms of primary parameter
  gradient <-  1 / variance * (sum(sample_data) - sample_size * mu)
  
  return(gradient)
}
```

<h4>Second Derivative Computation Methods</h4>
```{r}
# For log-likelihood of gamma distribution expressed in terms of alpha parameter
get_gamma_second_derivative <- function(W, X) { # W contains parameter; X is the sample_data
  
  # Extracting parameters from W into variables that better elucidate what they are
  alpha <- W
  
  # Computing size of sample data
  sample_size <- length(X)
  
  # second order derivative of log-likelihood function expressed in terms of primary parameter
  second_derivative <- sample_size * (1 / alpha - trigamma(alpha))
  
  return(second_derivative)
}
```

```{r}
# For log-likelihood of normal distribution expressed in terms of alpha parameter
get_normal_second_derivative <- function(W, X) { # W contains parameter; X is the sample_data
  
  # Extracting parameters from W into variables that better elucidate what they are
  mu <- W
  
  # Computing size of sample data
  sample_size <- length(X)
  
  variance <- sum((sample_data - mu) ^ 2) / sample_size
  # second order derivative of log-likelihood function expressed in terms of primary parameter
  second_derivative <-  sample_size * (-sample_size/ variance + 2 * (sum(sample_data) - sample_size * mu) / sum((sample_data - mu) ^ 3))
  
  return(second_derivative)
}
```

<h4>Newton-Raphson Iterative Descent Implementation</h4>
```{r}
# Looping stepwise_descent
newton_iteration_descent <- function(W, X, distribution_name, no_of_steps) { # record: A detailed history of weights, gradients, and second order derivatives at each step of Newton Iteration descent
  
  ### Code required just for record-keeping, not for Newton Iteration descent!
  table <- data.frame(matrix(ncol = 5, nrow = 0))
  colnames(table) <- c("Step_No", "Weight", "Gradient", "Second_Order_Derivative", "Subtrahend")
  ###
  
  i <- 1
  for (i in 1: no_of_steps) {
    
    if (distribution_name == "gamma") {
    
      gradient <- get_gamma_gradient(W, X)
      second_derivative <- get_gamma_second_derivative(W, X)
    
    } else if (distribution_name == "normal") {
    
      gradient <- get_normal_gradient(W, X)
      second_derivative <- get_normal_second_derivative(W, X)
    
    } else {
    
      print("Invalid distribution name")
    }
  
    subtrahend <- gradient/ second_derivative
    
    ### Code required just for record-keeping, not for Newton Iteration descent!
    record <- cbind(i, W, gradient, second_derivative, subtrahend)
    colnames(record) <- c("Step_No", "Weight", "Gradient", "Second_Order_Derivative", "Subtrahend")
    table <- rbind(table, record)
    ###
    
    W <- W - subtrahend
  }
  
  ### Code required just for record-keeping, not for Newton Iteration descent!
  if (distribution_name == "gamma") {
    
      gradient <- get_gamma_gradient(W, X)
      second_derivative <- get_gamma_second_derivative(W, X)
    
    } else if (distribution_name == "normal") {
    
      gradient <- get_normal_gradient(W, X)
      second_derivative <- get_normal_second_derivative(W, X)
    
    } else {
    
      print("Invalid distribution name")
    }
  
    subtrahend <- gradient/ second_derivative
  
  record <- cbind(i + 1, W, gradient, second_derivative, subtrahend)
  colnames(record) <- c("Step_No", "Weight", "Gradient", "Second_Order_Derivative",  "Subtrahend")
  table <- rbind(table, record)
  ### 
  
  weights_and_record <- list(W, table)
  names(weights_and_record) <- c("Final_Weights", "Record")
  
  return(weights_and_record)
}
```

<h3>Random Sample Generation Module</h3>
```{r}
get_sample <- function(sample_size, distribution_name, parameter_list) {
  if(sample_size > 0) {
    if(distribution_name == "normal") {
      sample_data <- rnorm(n = sample_size, mean = parameter_list$mu, sd = parameter_list$sigma)
  
    } else if (distribution_name == "binomial") {
      sample_data <- rbinom(n = sample_size, size = parameter_list$n, prob = parameter_list$prob)
    
    } else if (distribution_name == "poisson") {
      sample_data <- rpois(n = sample_size, lambda = parameter_list$lambda)
    
    } else if (distribution_name == "gamma") {
      sample_data <- rgamma(n = sample_size, shape = parameter_list$alpha, rate = parameter_list$beta)
    
    } else if (distribution_name == "beta") {
      sample_data <- rbeta(n = sample_size, shape1 = parameter_list$alpha, shape2 = parameter_list$beta)
    
    } else if (distribution_name == "exponential") {
      sample_data <- rexp(n = sample_size, rate = parameter_list$lambda)
    
    } else if (distribution_name == "geometric") {
      sample_data <- rgeom(n = sample_size, prob = parameter_list$prob)
    
    } else if (distribution_name == "uniform") {
      sample_data <- runif(n = sample_size, min = parameter_list$a, max = parameter_list$b)
    
    } else if (distribution_name == "multivariate") {
      sample_data <- mvrnorm(n = sample_size, mu = parameter_list$mu, Sigma = parameter_list$sigma)
      
    } else {
      print("Invalid distribution name")
    
    }
  } else {
    print("Invalid sample_size")
  }
  
  return(sample_data)
}
```

<h3>Testing Module</h3>
<h4>Generate Random Sample</h4>
```{r}
distribution_name = "gamma"
alpha <- 2
beta <- 1/3
parameter_list <- list(alpha, beta)
names(parameter_list) <- c("alpha", "beta")
sample_size <- 100
sample_data <- get_sample(sample_size = sample_size, distribution_name = distribution_name, parameter_list = parameter_list)
```
<h4>Compute alpha Using Newton Iteration Method</h4>
```{r}
alpha0 <- 1

weights <- c(alpha0)

weights_and_record <- newton_iteration_descent(weights, sample_data, distribution_name = distribution_name, no_of_steps = 10)
final_weights <- weights_and_record$Final_Weights
print(weights_and_record)
# print(final_weights)
```

```{r}
alpha <- final_weights[1]
beta <- alpha/ mean(sample_data)

print(paste("alpha estimate = ", alpha))
print(paste("beta estimate = ", beta))
```

<h4>Generate Random Sample</h4>
```{r}
# Get sample
distribution_name = "normal"
mu <- 1
sigma <- 4
parameter_list <- list(mu, sigma)
names(parameter_list) <- c("mu", "sigma")
sample_size <- 100
sample_data <- get_sample(sample_size = sample_size, distribution_name = distribution_name, parameter_list = parameter_list)
```

<h4>Compute mu Using Newton Iteration Method</h4>
```{r}
mu0 <- 0.5
weights <- c(mu0)

weights_and_record <- newton_iteration_descent(weights, sample_data, distribution_name = distribution_name, no_of_steps = 450)
final_weights <- weights_and_record$Final_Weights
print(weights_and_record)
# print(final_weights)
```

```{r}
mu <- final_weights[1]
sigma <- sqrt(sum((sample_data - mu) ^ 2) / sample_size)

print(paste("mu estimate = ", mu))
print(paste("sigma estimate = ", sigma))
```